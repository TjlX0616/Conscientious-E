---
tags:
  - 词嵌入
  - 机器学习
  - 编解码
  - 语言处理
---
**编码就是把一个文本里的token先变成独热编码，然后进行降维（相当于把输入的一句话根据语义，投射到一个==潜空间==，把高维空间里的对象投射到低维空间，这个过程就叫做==embedding即嵌入==）

嵌入的数据不一定是单词，但是在语言处理领域，主要就是针对单词/token，因而称为==词嵌入==，而把token投射到潜空间的那个矩阵就称为==嵌入矩阵==。

**潜空间就是一个没有符号、发音等形式上差别的非常纯粹的语义空间

以翻译为例：关键是要得到两个语言共同的潜空间，以这个潜空间为中介，就可以先把中文编码成潜空间里的对象，再把这个对象解码成英文，就能保证两种语言的语义一致。
	_NLP是神经语言程序学（Neuro-Linguistic Programming）


# Google的Word2Vec

**Word2Vec希望得到的结果是==嵌入矩阵==——不需要计算激活函数
### 方法一：CBOW
![[Pasted image 20250106111146.png]]
准备==奇数个token==，中间一个拿掉，剩下的与同一个嵌入矩阵相乘，把他们变成潜空间里的词向量，然后把这些词向量相加，对和向量进行解码。此时，损失函数就会定量的去看，和向量解码后得到的token和挖去的中间token是不是一样的。

### 方法二：skip-gram
![[Pasted image 20250106111341.png]]
**就是把CBOW的原理反过来用

